{"cells":[{"cell_type":"markdown","id":"1f97d444","metadata":{"id":"1f97d444"},"source":["[link text](https://)# Module 5 — Transfer Learning & Famous Architectures (Expanded)\n","\n","This expanded notebook demonstrates practical transfer learning workflows using ResNet50 and MobileNetV2 on CIFAR-10 (small subset for classroom demos). It includes:\n","\n","- dataset download and preprocessing\n","- augmentation pipeline\n","- feature-extraction (freeze backbone) training\n","- fine-tuning (unfreeze top layers)\n","- evaluation and model saving\n","\n","Notes: Use GPU runtime in Colab for faster training. Training epochs are kept small for demos."]},{"cell_type":"markdown","id":"7b59daa3","metadata":{"id":"7b59daa3"},"source":["## 1 — Setup (install packages and imports)"]},{"cell_type":"code","execution_count":null,"id":"c8a1b5bd","metadata":{"id":"c8a1b5bd"},"outputs":[],"source":["# Install / ensure tensorflow\n","!pip -q install -U tensorflow==2.12.0 --quiet\n","\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import layers, models\n","print('TF version:', tf.__version__)\n","print('GPU available:', tf.config.list_physical_devices('GPU'))\n"]},{"cell_type":"markdown","id":"00e5b6ae","metadata":{"id":"00e5b6ae"},"source":["## 2 — Load CIFAR-10 and prepare datasets (with augmentation)"]},{"cell_type":"code","execution_count":null,"id":"73293915","metadata":{"id":"73293915"},"outputs":[],"source":["from tensorflow.keras.datasets import cifar10\n","(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n","# reduce size for demo speed\n","x_train = x_train[:10000].astype('float32')\n","y_train = y_train[:10000]\n","x_test = x_test[:2000].astype('float32')\n","y_test = y_test[:2000]\n","\n","# Resize to backbone input size (224x224) and build tf.data\n","IMG_SIZE = 224\n","BATCH = 32\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","def preprocess(image, label, training=False):\n","    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n","    image = image / 255.0\n","    if training:\n","        image = tf.image.random_flip_left_right(image)\n","        image = tf.image.random_brightness(image, 0.1)\n","        image = tf.image.random_contrast(image, 0.9, 1.1)\n","    return image, label\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(lambda x,y: preprocess(x,y,training=True), num_parallel_calls=AUTOTUNE).shuffle(2000).batch(BATCH).prefetch(AUTOTUNE)\n","val_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).map(lambda x,y: preprocess(x,y,training=False), num_parallel_calls=AUTOTUNE).batch(BATCH).prefetch(AUTOTUNE)\n","\n","print('Sample batch shapes:')\n","for imgs, labs in train_ds.take(1):\n","    print(imgs.shape, labs.shape)\n"]},{"cell_type":"markdown","id":"3f26f053","metadata":{"id":"3f26f053"},"source":["## 3 — Build transfer learning model helper (ResNet50 / MobileNetV2)"]},{"cell_type":"code","execution_count":null,"id":"5248cb92","metadata":{"id":"5248cb92"},"outputs":[],"source":["from tensorflow.keras.applications import ResNet50, MobileNetV2\n","from tensorflow.keras import layers, models\n","\n","NUM_CLASSES = 10\n","\n","def build_transfer_model(backbone='resnet50', img_size=IMG_SIZE, num_classes=NUM_CLASSES):\n","    if backbone == 'resnet50':\n","        base = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size,img_size,3))\n","    elif backbone == 'mobilenetv2':\n","        base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_size,img_size,3))\n","    else:\n","        raise ValueError('Unsupported backbone')\n","    base.trainable = False\n","    inputs = layers.Input(shape=(img_size,img_size,3))\n","    x = base(inputs, training=False)\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.Dropout(0.3)(x)\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","    model = models.Model(inputs, outputs)\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Build ResNet model\n","model_resnet = build_transfer_model('resnet50')\n","model_resnet.summary()\n"]},{"cell_type":"markdown","id":"fb1a4918","metadata":{"id":"fb1a4918"},"source":["## 4 — Train classifier head (feature extraction) — ResNet50 example"]},{"cell_type":"code","execution_count":null,"id":"8d3367f2","metadata":{"id":"8d3367f2"},"outputs":[],"source":["# Train for a few epochs to demonstrate feature extraction\n","history_resnet = model_resnet.fit(train_ds, validation_data=val_ds, epochs=3)\n","plt.figure(figsize=(8,4))\n","plt.plot(history_resnet.history['val_accuracy'], label='val_acc')\n","plt.plot(history_resnet.history['accuracy'], label='train_acc')\n","plt.legend(); plt.title('ResNet feature-extractor training (few epochs)')\n","plt.show()\n"]},{"cell_type":"markdown","id":"1200c4a3","metadata":{"id":"1200c4a3"},"source":["## 5 — Evaluate ResNet feature-extractor"]},{"cell_type":"code","execution_count":null,"id":"4d67fac3","metadata":{"id":"4d67fac3"},"outputs":[],"source":["loss, acc = model_resnet.evaluate(val_ds)\n","print('ResNet val loss, acc:', loss, acc)\n"]},{"cell_type":"markdown","id":"998f10f8","metadata":{"id":"998f10f8"},"source":["## 6 — Fine-tune: unfreeze top layers and continue training (ResNet)"]},{"cell_type":"code","execution_count":null,"id":"5ba913ff","metadata":{"id":"5ba913ff"},"outputs":[],"source":["# Unfreeze last blocks for fine-tuning\n","base_model = model_resnet.layers[1]  # assuming base is second layer\n","# Safely set trainable for top layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","# Unfreeze last N layers\n","N = 30\n","for layer in base_model.layers[-N:]:\n","    layer.trainable = True\n","\n","model_resnet.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","# fine-tune for a few epochs\n","history_fine = model_resnet.fit(train_ds, validation_data=val_ds, epochs=2)\n","plt.plot(history_fine.history['val_accuracy'], label='val_acc_fine')\n","plt.legend(); plt.title('Fine-tuning')\n","plt.show()\n"]},{"cell_type":"markdown","id":"15c7eebd","metadata":{"id":"15c7eebd"},"source":["## 7 — Repeat with MobileNetV2 (feature extraction)"]},{"cell_type":"code","execution_count":null,"id":"db984ba0","metadata":{"id":"db984ba0"},"outputs":[],"source":["model_mobilenet = build_transfer_model('mobilenetv2')\n","history_mn = model_mobilenet.fit(train_ds, validation_data=val_ds, epochs=2)\n","print('MobileNetV2 training done')\n"]},{"cell_type":"markdown","id":"d511b6ec","metadata":{"id":"d511b6ec"},"source":["## 8 — Save models and tips for export"]},{"cell_type":"code","execution_count":null,"id":"4d267ac4","metadata":{"id":"4d267ac4"},"outputs":[],"source":["model_resnet.save('/mnt/data/resnet50_cifar10_head.h5')\n","model_mobilenet.save('/mnt/data/mobilenetv2_cifar10_head.h5')\n","print('Saved models to /mnt/data')\n","\n","# Quick note: to export to TFLite, use tf.lite.TFLiteConverter.from_keras_model(model)\n"]},{"cell_type":"markdown","id":"bf94f21c","metadata":{"id":"bf94f21c"},"source":["## 9 — Instructor exercises & notes\n","\n","- Try training longer and compare ResNet50 vs MobileNetV2 accuracy and training time.\n","- Observe memory / GPU usage: MobileNet is lighter and faster for edge demos.\n","- For class imbalance, demonstrate class weights or oversampling.\n","- Export model to SavedModel and TFLite for deployment demos."]}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}