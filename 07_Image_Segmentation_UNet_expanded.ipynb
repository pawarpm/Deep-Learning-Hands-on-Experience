{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec9b34f",
   "metadata": {},
   "source": [
    "# Module 7 — Image Segmentation (UNet) — Expanded\n",
    "\n",
    "This notebook demonstrates an end-to-end segmentation workflow using a tiny synthetic dataset of shapes (circles/rectangles) with binary masks. It includes:\n",
    "\n",
    "- creating synthetic images + masks\n",
    "- `tf.data` pipeline for segmentation (image, mask)\n",
    "- a simple UNet implementation in Keras\n",
    "- Dice + BCE loss, metrics\n",
    "- short training and visualization of predictions\n",
    "- saving the model\n",
    "\n",
    "This is classroom-friendly and runs quickly. Replace synthetic data with real masks for real projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d8071",
   "metadata": {},
   "source": [
    "## 1 — Setup (install packages and imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffcaed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install/ensure tensorflow\n",
    "!pip -q install -U tensorflow==2.12.0 --quiet\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "print('TF version:', tf.__version__)\n",
    "\n",
    "# create data folder\n",
    "os.makedirs('/mnt/data/seg_dataset/images', exist_ok=True)\n",
    "os.makedirs('/mnt/data/seg_dataset/masks', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd17894",
   "metadata": {},
   "source": [
    "## 2 — Create synthetic dataset (images + binary masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "\n",
    "def create_shape_image(path_img, path_mask, size=(128,128)):\n",
    "    img = Image.new('RGB', size, (255,255,255))\n",
    "    mask = Image.new('L', size, 0)\n",
    "    draw_img = ImageDraw.Draw(img)\n",
    "    draw_mask = ImageDraw.Draw(mask)\n",
    "    # randomly choose circle or rectangle\n",
    "    if random.random() < 0.5:\n",
    "        # circle\n",
    "        x0 = random.randint(16, size[0]//2)\n",
    "        y0 = random.randint(16, size[1]//2)\n",
    "        r = random.randint(16, min(size)//3)\n",
    "        bbox = [x0-r, y0-r, x0+r, y0+r]\n",
    "        draw_img.ellipse(bbox, fill=(random.randint(50,200), random.randint(50,200), random.randint(50,200)))\n",
    "        draw_mask.ellipse(bbox, fill=255)\n",
    "    else:\n",
    "        # rectangle\n",
    "        x1 = random.randint(8, size[0]//2)\n",
    "        y1 = random.randint(8, size[1]//2)\n",
    "        x2 = random.randint(size[0]//2, size[0]-8)\n",
    "        y2 = random.randint(size[1]//2, size[1]-8)\n",
    "        bbox = [x1,y1,x2,y2]\n",
    "        draw_img.rectangle(bbox, fill=(random.randint(50,200), random.randint(50,200), random.randint(50,200)))\n",
    "        draw_mask.rectangle(bbox, fill=255)\n",
    "    img.save(path_img)\n",
    "    mask.save(path_mask)\n",
    "\n",
    "# create dataset\n",
    "n_train = 80\n",
    "n_val = 20\n",
    "for i in range(n_train):\n",
    "    create_shape_image(f'/mnt/data/seg_dataset/images/train_{i}.png', f'/mnt/data/seg_dataset/masks/train_{i}.png')\n",
    "for i in range(n_val):\n",
    "    create_shape_image(f'/mnt/data/seg_dataset/images/val_{i}.png', f'/mnt/data/seg_dataset/masks/val_{i}.png')\n",
    "\n",
    "print('Created synthetic segmentation dataset with', n_train, 'train and', n_val, 'val samples')\n",
    "\n",
    "# show examples\n",
    "fig, axes = plt.subplots(2,3, figsize=(9,6))\n",
    "for i in range(3):\n",
    "    img = Image.open(f'/mnt/data/seg_dataset/images/train_{i}.png')\n",
    "    mask = Image.open(f'/mnt/data/seg_dataset/masks/train_{i}.png')\n",
    "    axes[0,i].imshow(img); axes[0,i].axis('off')\n",
    "    axes[1,i].imshow(mask, cmap='gray'); axes[1,i].axis('off')\n",
    "plt.suptitle('Sample images (top) and masks (bottom)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c57e9",
   "metadata": {},
   "source": [
    "## 3 — tf.data pipeline (image, mask pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "\n",
    "IMG_SIZE = (128,128)\n",
    "BATCH = 8\n",
    "\n",
    "image_paths = sorted(glob('/mnt/data/seg_dataset/images/*.png'))\n",
    "mask_paths = sorted(glob('/mnt/data/seg_dataset/masks/*.png'))\n",
    "\n",
    "# split by filenames (first n_train are train)\n",
    "train_images = image_paths[:n_train]\n",
    "train_masks = mask_paths[:n_train]\n",
    "val_images = image_paths[n_train:]\n",
    "val_masks = mask_paths[n_train:]\n",
    "\n",
    "def load_image_mask(img_path, mask_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    m = tf.io.read_file(mask_path)\n",
    "    m = tf.image.decode_png(m, channels=1)\n",
    "    m = tf.image.resize(m, IMG_SIZE)\n",
    "    m = tf.cast(m, tf.float32) / 255.0\n",
    "    return img, m\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_masks)).map(lambda x,y: load_image_mask(x,y), num_parallel_calls=tf.data.AUTOTUNE).shuffle(100).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_images, val_masks)).map(lambda x,y: load_image_mask(x,y), num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for imgs, masks in train_ds.take(1):\n",
    "    print('Batch shapes:', imgs.shape, masks.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb962f7",
   "metadata": {},
   "source": [
    "## 4 — Simple UNet implementation (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cdb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def conv_block(x, filters):\n",
    "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(x, filters):\n",
    "    c = conv_block(x, filters)\n",
    "    p = layers.MaxPooling2D((2,2))(c)\n",
    "    return c, p\n",
    "\n",
    "def decoder_block(x, skip, filters):\n",
    "    x = layers.UpSampling2D((2,2))(x)\n",
    "    x = layers.Concatenate()([x, skip])\n",
    "    x = conv_block(x, filters)\n",
    "    return x\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "# Encoder\n",
    "c1, p1 = encoder_block(inputs, 16)\n",
    "c2, p2 = encoder_block(p1, 32)\n",
    "c3, p3 = encoder_block(p2, 64)\n",
    "# Bottleneck\n",
    "bn = conv_block(p3, 128)\n",
    "# Decoder\n",
    "d3 = decoder_block(bn, c3, 64)\n",
    "d2 = decoder_block(d3, c2, 32)\n",
    "d1 = decoder_block(d2, c1, 16)\n",
    "outputs = layers.Conv2D(1, 1, activation='sigmoid')(d1)\n",
    "\n",
    "unet = models.Model(inputs, outputs)\n",
    "unet.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5defc08a",
   "metadata": {},
   "source": [
    "## 5 — Loss (BCE + Dice) and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46264f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "    dice = 1 - dice_coef(y_true, y_pred)\n",
    "    return bce + dice\n",
    "\n",
    "unet.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coef])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a6edb",
   "metadata": {},
   "source": [
    "## 6 — Train UNet (short demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 8\n",
    "history = unet.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n",
    "\n",
    "# plot metrics\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1); plt.plot(history.history['loss'], label='train_loss'); plt.plot(history.history['val_loss'], label='val_loss'); plt.legend(); plt.title('Loss')\n",
    "plt.subplot(1,2,2); plt.plot(history.history['dice_coef'], label='train_dice'); plt.plot(history.history['val_dice_coef'], label='val_dice'); plt.legend(); plt.title('Dice')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741039b",
   "metadata": {},
   "source": [
    "## 7 — Visualize predictions on validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc4588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "for imgs, masks in val_ds.take(2):\n",
    "    preds = unet.predict(imgs)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for i in range(min(6, imgs.shape[0])):\n",
    "        plt.subplot(3,6,i+1); plt.imshow(imgs[i]); plt.axis('off'); plt.title('Image')\n",
    "        plt.subplot(3,6,i+7); plt.imshow(masks[i,:,:,0], cmap='gray'); plt.axis('off'); plt.title('Mask')\n",
    "        plt.subplot(3,6,i+13); plt.imshow(preds[i,:,:,0]>0.5, cmap='gray'); plt.axis('off'); plt.title('Pred >0.5')\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c151c5",
   "metadata": {},
   "source": [
    "## 8 — Save model and tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.save('/mnt/data/unet_synthetic.h5')\n",
    "print('Saved UNet to /mnt/data/unet_synthetic.h5')\n",
    "\n",
    "# Tips: Replace synthetic dataset with real image/mask pairs; adjust model capacity for real tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45967ca7",
   "metadata": {},
   "source": [
    "## 9 — Exercises & Instructor Notes\n",
    "\n",
    "- Replace synthetic dataset with a real segmentation dataset (e.g., plant leaf segmentation) and re-run training.\n",
    "- Try different loss functions (Dice loss alone, Focal loss) for class imbalance.\n",
    "- Show morphological post-processing (opening/closing) on predicted masks to clean artifacts.\n",
    "- Export model to SavedModel or TFLite for deployment demos.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
