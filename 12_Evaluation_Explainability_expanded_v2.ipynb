{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e7c1d1",
   "metadata": {},
   "source": [
    "# Module 12 — Model Evaluation, Explainability & Debugging (v2)\n",
    "\n",
    "Updated notebook with clear sections and lightweight explainability examples suitable for classroom demos. Includes:\n",
    "\n",
    "- classification metrics (confusion matrix, ROC, PR)\n",
    "- SHAP for tabular models (small sample + bar plot)\n",
    "- Grad-CAM for CNNs (single-image overlay)\n",
    "- debugging checklist and classroom exercises\n",
    "\n",
    "This version uses small datasets and is careful to keep computations light for Colab demos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02c2c04",
   "metadata": {},
   "source": [
    "## 1 — Setup (install packages and imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbeec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install minimal required packages\n",
    "!pip -q install -U tensorflow scikit-learn shap matplotlib --quiet\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "import shap\n",
    "print('TF version:', tf.__version__)\n",
    "print('SHAP version:', shap.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26be7a2",
   "metadata": {},
   "source": [
    "## 2 — Tabular baseline model & evaluation (RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small synthetic dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_classification(n_samples=300, n_features=8, n_informative=4, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train RandomForest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict & metrics\n",
    "y_pred = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)[:,1]\n",
    "print('Classification report:\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix:\\n', cm)\n",
    "\n",
    "# ROC & PR\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(fpr, tpr, label=f'ROC AUC={roc_auc:.2f}')\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Curve'); plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(rec, prec); plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a3f11",
   "metadata": {},
   "source": [
    "## 3 — SHAP explanation (lightweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53afb0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a small background dataset to keep SHAP fast\n",
    "background = X_train[np.random.choice(X_train.shape[0], size=min(50, X_train.shape[0]), replace=False)]\n",
    "explainer = shap.Explainer(rf.predict_proba, background)\n",
    "# explain a few test instances only\n",
    "to_explain = X_test[:10]\n",
    "shap_values = explainer(to_explain)\n",
    "\n",
    "# Use a compact bar plot for feature importance across the explained samples\n",
    "shap.plots.bar(shap_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf209a3b",
   "metadata": {},
   "source": [
    "## 4 — Grad-CAM for CNNs (Keras) — single-image demo on CIFAR-10 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d16ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train a tiny CNN on a small CIFAR-10 subset, then compute Grad-CAM for one image\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "x_train = x_train[:1500].astype('float32')/255.0; y_train = y_train[:1500]\n",
    "x_test = x_test[:300].astype('float32')/255.0; y_test = y_test[:300]\n",
    "\n",
    "def tiny_cnn():\n",
    "    inputs = layers.Input((32,32,3))\n",
    "    x = layers.Conv2D(16,3,activation='relu', name='conv1')(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(32,3,activation='relu', name='conv2')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "model = tiny_cnn()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Pick a sample image\n",
    "idx = 5\n",
    "img = x_test[idx:idx+1]\n",
    "probs = model.predict(img)\n",
    "pred_class = np.argmax(probs[0])\n",
    "print('Predicted class:', pred_class)\n",
    "\n",
    "# Grad-CAM\n",
    "last_conv_layer_name = 'conv2'\n",
    "grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(img)\n",
    "    loss = predictions[:, pred_class]\n",
    "\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0,1))\n",
    "conv_outputs = conv_outputs[0].numpy()\n",
    "pooled_grads = pooled_grads.numpy()\n",
    "\n",
    "# Weight the channels by pooled grads\n",
    "for i in range(pooled_grads.shape[-1]):\n",
    "    conv_outputs[:,:,i] *= pooled_grads[i]\n",
    "heatmap = np.mean(conv_outputs, axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= (np.max(heatmap) + 1e-8)\n",
    "\n",
    "# resize heatmap to 32x32 and overlay\n",
    "import cv2\n",
    "heatmap_resized = cv2.resize(heatmap, (32,32))\n",
    "heatmap_uint = np.uint8(255 * heatmap_resized)\n",
    "heatmap_color = cv2.applyColorMap(heatmap_uint, cv2.COLORMAP_JET)\n",
    "superimposed = heatmap_color * 0.4 + np.uint8(img[0]*255)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1); plt.imshow(img[0]); plt.title('Original'); plt.axis('off')\n",
    "plt.subplot(1,2,2); plt.imshow(superimposed.astype('uint8')); plt.title('Grad-CAM'); plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3694ff5d",
   "metadata": {},
   "source": [
    "## 5 — Debugging checklist & classroom exercises\n",
    "\n",
    "**Checklist**\n",
    "- Data leakage: check splits and ensure no overlap.\n",
    "- Label noise: sample and inspect potentially wrong labels.\n",
    "- Class imbalance: compute class distribution; consider class weights or resampling.\n",
    "- Learning rate and optimization: try different optimizers or learning rate schedules.\n",
    "- Overfitting: compare train/val curves, use augmentation or regularization.\n",
    "\n",
    "**In-class exercises**\n",
    "1. Run SHAP on a misclassified example and interpret which features pushed the prediction.\n",
    "2. Use Grad-CAM on several misclassified images and discuss what the model focuses on.\n",
    "3. Introduce a synthetic label noise (flip 5% labels) and observe effect on model performance.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
